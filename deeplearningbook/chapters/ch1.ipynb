{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Artifical Intelligence\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; **Artificial Intelligence (AI)** is a branch of computer science focused on creating systems that perform tasks that require human-like intelligence, such as language comprehension, pattern recognition, problem-solving, and decision-making. AI is a broad and evolving field that encompasses numerous subfields and applications. In this book, we will focus on machine learning, specifically deep learning.\n",
    "\n",
    "```{figure} ../images/deep-learning.png\n",
    "---\n",
    "width: 140px\n",
    "name: deep-learning\n",
    "---\n",
    "Deep Learning Overview\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Machine Learning \n",
    "**Machine Learning (ML)** is a subset of AI focused on creating algorithms, known as **models**, that learn patterns from data through training and are able to make predictions or decisions without explicit programming. The main machine learning approaches are:\n",
    "\n",
    "- **Supervised Learning**: The model is trained on labeled data, meaning each input example in the training set has an associted label. The model learns to associate inputs with outputs, making it well-suited for classification and regression tasks.\n",
    "- **Unsupervised Learning**: The model is trained on unlabeled data, where input examples do not have labels. The model learns to identify hidden patterns or groupings within the data, making it well-suited for clustering and association tasks.\n",
    "- **Reinforcement Learning**: The model learns through rewards and penalties based on its actions, making it well-suited for environments where decision-making is complex, such as strategic games and robotics.\n",
    "\n",
    "In addition to these core approaches, there are more specific modeling techniques that can be applied within the context of supervised and unsupervised learning such as discriminative modeling and generative modeling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Discriminative modeling\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; **Discriminative modeling** is closely related to supervised learning, as it uses label data. Discriminative models focus on learning the decision boundary between different classes or outputs in the training data. They predict the probability of a label $y$ given an input example $x$, represented mathematically as $p(y|x)$.\n",
    "\n",
    "```{figure} ../images/discriminative-model.png\n",
    "---\n",
    "width: 510px\n",
    "name: discriminative-model\n",
    "---\n",
    "Discriminative Model\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## Generative modeling\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; **Generative modeling** is related to both supervised and unsupervised learning, as it tipically uses labeln and unlabeled data. Generative models focus on learning the underlying probability distribution of the training data, that explains why certain examples are more probable than others. They can generate new samples similar to the original data by estimating $p(x)$, the probability of the input example itself.\n",
    "\n",
    "```{important}\n",
    "A generative model is probabilistic rather than deterministic because it aims to produce diverse variations of a result, rather than yielding the same outcome every time. To achieve this, a generative model incorporates a random component, such as random noise, which influences the samples generated by the model.\n",
    "```\n",
    "\n",
    "```{figure} ../images/generative-model.png\n",
    "---\n",
    "width: 510px\n",
    "name: generative-model\n",
    "---\n",
    "Generative Model\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Deep Learning\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; **Deep Learning (DL)** is a specialized area within ML that employs systems with multiple layers to progressively extract features and identify intricate patterns in large datasets. **Neural networks**, based on this principle, have revolutionized AI by solving complex problems that traditional ML models cannot handle. For instance, detecting a dog in a picture is nearly impossible with conventional approaches like logistic regression or random forests. However, with a large dataset of labeled dog images, neural networks can easily accomplish this task.\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; Furthermore, ML models typically require structured data arranged in tables, where each column represents a feature and each row is an instance. Working with **unstructured data** is far more challenging because individual components (e.g., pixels in an image, frequencies in audio, or characters in text) lack meaningful information on their own. For example, knowing the color of a single pixel does not reveal whether an image contains a dog. In addition, factors like the dog's position in the image or its breed should not affect the result, as the image still contains a dog. Neural networks are able to generalize patterns and extract meaningful information despite the granularity and spatial dependencies inherent in unstructured data.\n",
    "\n",
    "```{figure} ../images/unstructured-data.png\n",
    "---\n",
    "width: 510px\n",
    "name: unstructured-data\n",
    "---\n",
    "Unstructured Data\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Neural Networks\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; **Neural networks** are computational models inspired by the structure of the human brain, designed to recognize patterns and make predictions. They consist of layers of interconnected nodes (often called neurons) that process information through mathematical operations.\n",
    "\n",
    "A basic neural network has the following structure:\n",
    "\n",
    "1. **Input Layer**: The first layer receives raw data, like images, text, or numerical values. Each node in this layer represents an input dimension.\n",
    "2. **Hidden Layers**: The intermediate layers are between the input and output layers, and process the information. Each hidden layer transforms data from the previous layer, allowing the network to progressively learn and recognize patterns.\n",
    "3. **Output Layer**: The final layer provides the networkâ€™s output, such as classifying an image or predicting a value.\n",
    "\n",
    "```{figure} ../images/neural-network.png\n",
    "---\n",
    "width: 340px\n",
    "name: neural-network\n",
    "---\n",
    "Basic Structure of a Neural Network\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(1.3)=\n",
    "## Neurons\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; A **neuron** is a fundamental unit that takes in multiple inputs and processes them to produce a single output. As shown above in [*Fig. 1.2*](neural-network), each neuron in the hidden and output layers connects to all the neurons in the previous layer. These connections have associated values, known as **weights**, which are adjusted by the model. The weights represent the strength of connection between the neurons. A greater weight indicates a stronger connection.\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; To calculate the output of a neuron, all the inputs to the neuron ($x_{1}, x_{2}, \\dots, x_{d}$) are multiplied by their corresponding connection weights ($w_{1}, w_{2}, \\dots, w_{d}$), and the products are summed. A numerical value, called the **bias** ($b$), is then added to the weighted sum. Finally, the result is passed through an **activation function** ($\\sigma$) that returns the output of the neuron, often called the neuron's **activation value** ($h$).\n",
    "\n",
    "```{figure} ../images/neuron.png\n",
    "---\n",
    "width: 250px\n",
    "name: neuron\n",
    "---\n",
    "Structure of a Neuron\n",
    "```\n",
    "\n",
    "```{admonition} Neuron's output\n",
    "<p class=\"bottom-margin\">The activation value of a neuron is given by the formula:</p>\n",
    "\n",
    "$$\n",
    "\\small\n",
    "h = \\sigma(x_{1}w_{1} + x_{2}w_{2} + \\dots + x_{d}w_{d} + b)\n",
    "$$\n",
    "\n",
    "<p class=\"no-top-margin\">where:</p>\n",
    "\n",
    "- $d$: Dimensionality of the input vector.\n",
    "```\n",
    "\n",
    "\n",
    "```{admonition} Neuron's output (dot product)\n",
    "<p class=\"bottom-margin\">Using a dot product to express the weighted sum, the formula is:</p>\n",
    "\n",
    "$$\n",
    "\\small\n",
    "h\n",
    "=\n",
    "\\sigma\\left(\n",
    "\\begin{bmatrix}\n",
    "x_{1} & x_{2} & \\dots & x_{d}\n",
    "\\end{bmatrix}\n",
    "\\cdot\n",
    "\\begin{bmatrix}\n",
    "w_{1} \\\\\n",
    "w_{2} \\\\\n",
    "\\vdots \\\\\n",
    "w_{d}\n",
    "\\end{bmatrix}\n",
    "+\n",
    "b\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "<p class=\"no-top-margin\">where:</p>\n",
    "\n",
    "- $d$: Dimensionality of the input vector.\n",
    "```\n",
    "\n",
    "```{important}\n",
    "Please note that the ouput of a neuron is one of the inputs to all the neurons in the next layer.\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## PyTorch\n",
    "\n",
    "&ensp; &ensp; &ensp; &ensp; To build our neural networks, we will use **PyTorch**, an open-source machine learning library widely used because of its flexibility, ease of use, and efficient computation.\n",
    "\n",
    "````{admonition} PyTorch Tensors\n",
    "<p style=\"margin: 15px 1.4rem  15px 1.4rem ;\">PyTorch provides <strong>tensors</strong>, which are multi-dimensional arrays optimized for GPU processing. Depending on their dimensions, we will refer to them differently:</p>\n",
    "\n",
    "- A 1-dimensional tensor is called a **vector**. A vector with shape (3) would look like this:\n",
    "\n",
    "```python\n",
    "tensor([1, 2, 3])\n",
    "```\n",
    "\n",
    "- A 2-dimensional tensor is called a **matrix**. A matrix with shape (2, 3) would look like this:\n",
    "\n",
    "```python\n",
    "tensor([[1, 2, 3],\n",
    "        [4, 5, 6]])\n",
    "```\n",
    "\n",
    "- A 3 or more dimensional tensor is called an **n-dimensional tensor**. A 3-dimensional tensor with shape (2, 2, 3) would look like this:\n",
    "\n",
    "```python\n",
    "tensor([[[1, 2, 3],\n",
    "        [4, 5, 6]],\n",
    "        [[7, 8, 9],\n",
    "        [10, 11, 12]]])\n",
    "```\n",
    "````\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
